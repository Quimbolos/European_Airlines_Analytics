{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
      "/var/folders/9j/r5th0fxd26341bbn6qkwvlww0000gn/T/ipykernel_9822/2687544457.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to remove numericals and spaces at the front and back\n",
    "def clean_string(s):\n",
    "    return s.str.replace(r'^[0-9\\s]+|[0-9\\s]+$', '')\n",
    "\n",
    "# List of all the airlines folders and corresponding csv names\n",
    "airline_folders = ['1 Ryanair', '2 Lufthansa', '3 International Airlines Group', '4 AirFrance-KLM',\n",
    "                   '5 Turkish Airlines', '6 EasyJet', '7 WizzAir', '8 Aeroflot Group', '9 Pegasus Airlines', '10 SAS Group']\n",
    "\n",
    "airline_csv_names = ['ryanair', 'lufthansa', 'iag', 'airfrance_klm',\n",
    "                   'turkish_airlines', 'easyjet', 'wizzair', 'aeroflot_group', 'pegasus_airlines', 'sas_scandinavian_airlines']\n",
    "\n",
    "# Output folder\n",
    "output_folder = 'all_airlines'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Define the types of datasets\n",
    "dataset_types = ['reviews', 'reviews_sentiment_analysis', 'reviews_sentiment_analysis_lemmatized', 'reviews_routesummary']\n",
    "\n",
    "# Dictionary to store DataFrames\n",
    "all_dfs = {}\n",
    "\n",
    "# Loop through each airline folder and its corresponding csv name\n",
    "for airline, airline_name in zip(airline_folders, airline_csv_names):\n",
    "    airline_folder_path = os.path.join(airline, 'data')\n",
    "\n",
    "    # Loop through each dataset type\n",
    "    for dataset_type in dataset_types:\n",
    "        # Read the current dataset type\n",
    "        current_df = pd.read_csv(os.path.join(airline_folder_path, f'{airline_name}_{dataset_type}.csv'))\n",
    "        current_df['airline'] = airline\n",
    "\n",
    "        # Apply cleaning function\n",
    "        current_df['airline'] = clean_string(current_df['airline'])\n",
    "\n",
    "        # Reset index and drop 'Unnamed: 0'\n",
    "        current_df.reset_index(inplace=True, drop=False)\n",
    "        current_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        key = f'all_airlines_{dataset_type}'\n",
    "        if key in all_dfs:\n",
    "            all_dfs[key].append(current_df)\n",
    "        else:\n",
    "            all_dfs[key] = [current_df]\n",
    "\n",
    "# Concatenate DataFrames for each dataset type\n",
    "for key, dfs in all_dfs.items():\n",
    "    all_dfs[key] = pd.concat(dfs)\n",
    "\n",
    "# Save DataFrames to CSV\n",
    "for key, df in all_dfs.items():\n",
    "    df.to_csv(os.path.join(output_folder, f'{key}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10984 entries, 0 to 10983\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   index                      10984 non-null  int64  \n",
      " 1   authors                    10984 non-null  object \n",
      " 2   countries                  10984 non-null  object \n",
      " 3   date                       10984 non-null  object \n",
      " 4   rating                     10984 non-null  int64  \n",
      " 5   reviews                    10984 non-null  object \n",
      " 6   aircraft                   4608 non-null   object \n",
      " 7   traveller type             10982 non-null  object \n",
      " 8   seat type                  10984 non-null  object \n",
      " 9   route                      10950 non-null  object \n",
      " 10  date flown                 10983 non-null  object \n",
      " 11  seat comfort               10129 non-null  float64\n",
      " 12  cabin staff service        10076 non-null  float64\n",
      " 13  food & beverages           7522 non-null   float64\n",
      " 14  inflight entertainment     5220 non-null   float64\n",
      " 15  ground service             10488 non-null  float64\n",
      " 16  wifi                       3174 non-null   float64\n",
      " 17  value for money            10983 non-null  float64\n",
      " 18  recommended                10984 non-null  object \n",
      " 19  verified                   10984 non-null  bool   \n",
      " 20  start airport              10938 non-null  object \n",
      " 21  end airport                10943 non-null  object \n",
      " 22  transfer airport           3112 non-null   object \n",
      " 23  sentiment analysis         10984 non-null  object \n",
      " 24  sentiment analysis scores  10984 non-null  float64\n",
      " 25  lemmatized reviews         10984 non-null  object \n",
      " 26  airline                    10984 non-null  object \n",
      "dtypes: bool(1), float64(8), int64(2), object(16)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the appropiate\n",
    "all_df = pd.read_csv(os.path.join('all_airlines', 'all_airlines_reviews_sentiment_analysis_lemmatized.csv'))\n",
    "all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling\n",
    "\n",
    "from gensim import corpora, models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ryanair: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "pay time check seat get fly board hour airport staff\n",
      "\n",
      "2 Lufthansa: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "seat frankfurt service time get good hour class business food\n",
      "\n",
      "3 International Airlines Group: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "seat ba service get time london good hour crew food\n",
      "\n",
      "4 AirFrance-KLM: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "seat amsterdam service time get fly good hour crew food\n",
      "\n",
      "5 Turkish Airlines: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "istanbul seat service hour time ticket get airport staff customer\n",
      "\n",
      "6 EasyJet: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "time delay bag board hour get staff seat us fly\n",
      "\n",
      "7 WizzAir: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "pay air check time airport fly seat get hour service\n",
      "\n",
      "8 Aeroflot Group: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "moscow good seat time service hour food get staff fly\n",
      "\n",
      "9 Pegasus Airlines: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "istanbul time pay hour staff get seat delay ticket us\n",
      "\n",
      "10 SAS Group: LDA with lemmatized reviews\n",
      "Topic #1:\n",
      "sa seat service sas get time fly copenhagen hour good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Topic Modelling Code for All reviews\n",
    "\n",
    "# List of all the airlines folders and corresponding csv names\n",
    "airline_folders = ['1 Ryanair', '2 Lufthansa', '3 International Airlines Group', '4 AirFrance-KLM',\n",
    "                   '5 Turkish Airlines', '6 EasyJet', '7 WizzAir', '8 Aeroflot Group', '9 Pegasus Airlines', '10 SAS Group']\n",
    "\n",
    "airline_csv_names = ['ryanair', 'lufthansa', 'iag', 'airfrance_klm',\n",
    "                   'turkish_airlines', 'easyjet', 'wizzair', 'aeroflot_group', 'pegasus_airlines', 'sas_scandinavian_airlines']\n",
    "\n",
    "# Define the types of datasets\n",
    "filename = 'reviews_sentiment_analysis_lemmatized'\n",
    "\n",
    "\n",
    "# Loop through each airline folder and its corresponding csv name\n",
    "for airline, airline_name in zip(airline_folders, airline_csv_names):\n",
    "    airline_folder_path = os.path.join(airline, 'data')\n",
    "\n",
    "    # Read the current dataset type\n",
    "    current_df = pd.read_csv(os.path.join(airline_folder_path, f'{airline_name}_{filename}.csv'))\n",
    "\n",
    "    # # Apply cleaning function\n",
    "    # current_df['airline'] = clean_string(current_df['airline'])\n",
    "\n",
    "    # # Reset index and drop 'Unnamed: 0'\n",
    "    # current_df.reset_index(inplace=True, drop=False)\n",
    "    # current_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    # Create a document-term matrix using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "    tfidf_lemma = tfidf_vectorizer.fit_transform(current_df['lemmatized reviews'])\n",
    "\n",
    "    # Perform LDA topic modeling\n",
    "    num_topics = 1\n",
    "    lda_lemma = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda_lemma.fit(tfidf_lemma)\n",
    "\n",
    "    # Display the topics and associated words\n",
    "    def print_top_words(model, feature_names, n_top_words):\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            print(f\"Topic #{topic_idx + 1}:\")\n",
    "            print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "            print()\n",
    "\n",
    "    n_top_words = 10\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    print(f'{airline}: LDA with lemmatized reviews')\n",
    "    print_top_words(lda_lemma, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ryanair: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "pay check get fly time seat hour us bag airport\n",
      "\n",
      "2 Lufthansa: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "seat service frankfurt time get hour customer fly us airport\n",
      "\n",
      "3 International Airlines Group: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "seat ba service get hour london class time us fly\n",
      "\n",
      "4 AirFrance-KLM: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "seat get service amsterdam luggage hour time us customer fly\n",
      "\n",
      "5 Turkish Airlines: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "istanbul seat ticket hour service get time us customer airport\n",
      "\n",
      "6 EasyJet: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "delay bag hour time get pay us staff fly luggage\n",
      "\n",
      "7 WizzAir: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "pay check air airport get hour fly time service us\n",
      "\n",
      "8 Aeroflot Group: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "moscow hour get time luggage seat refund airport day delay\n",
      "\n",
      "9 Pegasus Airlines: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "istanbul pay hour time us staff get ticket delay airport\n",
      "\n",
      "10 SAS Group: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "sa service get seat sas time hour fly customer copenhagen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Topic Modelling Code for Non-Recommended Reviews\n",
    "\n",
    "# List of all the airlines folders and corresponding csv names\n",
    "airline_folders = ['1 Ryanair', '2 Lufthansa', '3 International Airlines Group', '4 AirFrance-KLM',\n",
    "                   '5 Turkish Airlines', '6 EasyJet', '7 WizzAir', '8 Aeroflot Group', '9 Pegasus Airlines', '10 SAS Group']\n",
    "\n",
    "airline_csv_names = ['ryanair', 'lufthansa', 'iag', 'airfrance_klm',\n",
    "                   'turkish_airlines', 'easyjet', 'wizzair', 'aeroflot_group', 'pegasus_airlines', 'sas_scandinavian_airlines']\n",
    "\n",
    "# Define the types of datasets\n",
    "filename = 'reviews_sentiment_analysis_lemmatized'\n",
    "\n",
    "\n",
    "# Loop through each airline folder and its corresponding csv name\n",
    "for airline, airline_name in zip(airline_folders, airline_csv_names):\n",
    "    airline_folder_path = os.path.join(airline, 'data')\n",
    "\n",
    "    # Read the current dataset type\n",
    "    current_df = pd.read_csv(os.path.join(airline_folder_path, f'{airline_name}_{filename}.csv'))\n",
    "\n",
    "    # Only use the non recommended columns\n",
    "    current_df_neg_reviews = current_df[current_df['recommended'] == 'no']\n",
    "\n",
    "    # Create a document-term matrix using TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "    tfidf_lemma = tfidf_vectorizer.fit_transform(current_df_neg_reviews['lemmatized reviews'])\n",
    "\n",
    "    # Perform LDA topic modeling\n",
    "    num_topics = 1\n",
    "    lda_lemma = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    lda_lemma.fit(tfidf_lemma)\n",
    "\n",
    "    # Display the topics and associated words\n",
    "    def print_top_words(model, feature_names, n_top_words):\n",
    "        for topic_idx, topic in enumerate(model.components_):\n",
    "            print(f\"Topic #{topic_idx + 1}:\")\n",
    "            print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "            print()\n",
    "\n",
    "    n_top_words = 10\n",
    "    tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    print(f'{airline}: LDA with lemmatized non recommended reviews')\n",
    "    print_top_words(lda_lemma, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Airlines: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "seat get hour service time pay us fly customer check\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the appropiate\n",
    "all_df = pd.read_csv(os.path.join('all_airlines', 'all_airlines_reviews_sentiment_analysis_lemmatized.csv'))\n",
    "\n",
    "# Only use the non recommended columns\n",
    "df_neg_reviews = all_df[all_df['recommended'] == 'no']\n",
    "\n",
    "# Create a document-term matrix using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf_lemma = tfidf_vectorizer.fit_transform(df_neg_reviews['lemmatized reviews'])\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "num_topics = 1\n",
    "lda_lemma = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_lemma.fit(tfidf_lemma)\n",
    "\n",
    "# Display the topics and associated words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "n_top_words = 10\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print('All Airlines: LDA with lemmatized non recommended reviews')\n",
    "print_top_words(lda_lemma, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Airlines: LDA with lemmatized recommended reviews\n",
      "Topic #1:\n",
      "seat time service get hour fly pay staff us good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the appropiate\n",
    "all_df = pd.read_csv(os.path.join('all_airlines', 'all_airlines_reviews_sentiment_analysis_lemmatized.csv'))\n",
    "\n",
    "# Create a document-term matrix using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf_lemma = tfidf_vectorizer.fit_transform(all_df['lemmatized reviews'])\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "num_topics = 1\n",
    "lda_lemma = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_lemma.fit(tfidf_lemma)\n",
    "\n",
    "# Display the topics and associated words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "n_top_words = 10\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print('All Airlines: LDA with lemmatized recommended reviews')\n",
    "print_top_words(lda_lemma, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Airlines: LDA with lemmatized non recommended reviews\n",
      "Topic #1:\n",
      "seat good time crew service cabin board food fly staff\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the appropiate\n",
    "all_df = pd.read_csv(os.path.join('all_airlines', 'all_airlines_reviews_sentiment_analysis_lemmatized.csv'))\n",
    "\n",
    "# Only use the recommended columns\n",
    "df_neg_reviews = all_df[all_df['recommended'] == 'yes']\n",
    "\n",
    "# Create a document-term matrix using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2)\n",
    "tfidf_lemma = tfidf_vectorizer.fit_transform(df_neg_reviews['lemmatized reviews'])\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "num_topics = 1\n",
    "lda_lemma = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_lemma.fit(tfidf_lemma)\n",
    "\n",
    "# Display the topics and associated words\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "n_top_words = 10\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "print('All Airlines: LDA with lemmatized non recommended reviews')\n",
    "print_top_words(lda_lemma, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b64a52f329bd7ac83fd7355bf526de5da9b8503da8fcdfb6f417a855f85dd2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
